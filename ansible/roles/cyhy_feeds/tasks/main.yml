---
# tasks file for cyhy_feeds

#
# Grab and copy some secrets from S3
#
- name: Grab secrets from S3
  local_action:
    module: aws_s3
    bucket: ncats-cyhy-secrets
    object: "{{ item }}"
    dest: "/tmp/{{ item }}"
    mode: get
  become: no
  loop:
    - cyhy-data-extract.cfg
    - ncats_lab_public_gpg.key
    - ncats_lab_private_gpg.key
    - nsd_cyhy_daily_extract_public.key
    - gpg_keys.trust

- name: Copy secrets
  copy:
    src: "/tmp/{{ item }}"
    dest: "/var/cyhy/scripts/cyhy-feeds/{{ item }}"
    mode: 0444
    owner: cyhy
    group: cyhy
  loop:
    - cyhy-data-extract.cfg
    - ncats_lab_public_gpg.key
    - ncats_lab_private_gpg.key
    - nsd_cyhy_daily_extract_public.key
    - gpg_keys.trust

#
# Import keys and trust
#

# The --batch flag makes sure that gpg2 doesn't attempt to do anything
# interactive.
- name: Import gpg keys
  shell: "gpg2 --trustdb-name /var/cyhy/.gnupg/trustdb.gpg --import --batch /var/cyhy/scripts/cyhy-feeds/{{ item }}"
  become_user: cyhy
  vars:
    ansible_ssh_pipelining: yes
  loop:
    - ncats_lab_public_gpg.key
    - ncats_lab_private_gpg.key
    - nsd_cyhy_daily_extract_public.key

- name: Import gpg trust
  shell: "gpg2 --import-ownertrust --batch /var/cyhy/scripts/cyhy-feeds/gpg_keys.trust"
  become_user: cyhy
  vars:
    ansible_ssh_pipelining: yes

#
# Cleanup
#
- name: Delete local copies of secrets
  local_action:
    module: file
    path: "/tmp/{{ item }}"
    state: absent
  become: no
  loop:
    - cyhy-data-extract.cfg
    - ncats_lab_public_gpg.key
    - ncats_lab_private_gpg.key
    - nsd_cyhy_daily_extract_public.key
    - gpg_keys.trust

#
# Create /etc/cyhy/cyhy.conf file
#
- name: Grab mongo users from S3
  local_action:
    module: aws_s3
    bucket: ncats-cyhy-secrets
    object: mongo_users.yml
    dest: /tmp/mongo_users.yml
    mode: get
  become: no

- name: Load mongo users token from YML file
  local_action:
    module: include_vars
    file: /tmp/mongo_users.yml
    name: mongo_users

- name: Create /etc/cyhy directory
  file:
    path: /etc/cyhy
    state: directory

- name: Check if cyhy.conf already exists
  stat:
    path: /etc/cyhy/cyhy.conf
  register: cyhy_conf_result

- name: Create cyhy.conf with commander credentials if it doesn't already exist
  copy:
    dest: /etc/cyhy/cyhy.conf
    owner: cyhy
    group: cyhy
    mode: 0660
    content: |
      [DEFAULT]
      default-section = production
      database-uri = mongodb://localhost:27017/
      report-key =

      [production]
      database-uri = mongodb://commander:{{ mongo_users.other_users | selectattr("user", "eq", "commander") | map(attribute="password") | first }}@database1:27017/cyhy
      database-name = cyhy

      [production_bod_scan]
      database-uri = mongodb://scan-reader:{{ mongo_users.other_users | selectattr("user", "eq", "scan-reader") | map(attribute="password") | first }}@database1:27017/scan
      database-name = scan
  when: cyhy_conf_result.stat.exists == False

- name: Check if desired additions are in cyhy.conf and if not append them
  lineinfile:
    dest: /etc/cyhy/cyhy.conf
    line: '{{ item }}'
  with_items:
    - '[production_bod_scan]'
    - database-uri = mongodb://scan-reader:{{ mongo_users.other_users | selectattr("user", "eq", "scan-reader") | map(attribute="password")| first }}@database1:27017/scan
    - 'database-name = scan'

#
# Create a cron job to run the extract script nightly at 0815 (UTC) as
# cyhy
#
- name: Set up nightly cron job to sync NSD data for MOE extract
  cron:
    name: Nightly cyhy extract
    hour: 08
    minute: 15
    user: cyhy
    job: cd /var/cyhy/scripts/cyhy-feeds && python2.7 /var/cyhy/scripts/cyhy-feeds/cyhy-data-extract.py --cyhy_section production --bod_section production_bod_scan --aws --config /var/cyhy/scripts/cyhy-feeds/cyhy-data-extract.cfg
